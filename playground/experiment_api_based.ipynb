{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iidIX51ST3Fu"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai chromadb tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "i_X_ReI2TqW7"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.schema.document import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "XRvP73WeUA_A"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "loader = TextLoader(\"devfest_info.txt\")\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c039tISpOe3w"
      },
      "source": [
        "##Method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "fKBDz-m-E4_N"
      },
      "outputs": [],
      "source": [
        "chunk_size = 200\n",
        "overlap = 50\n",
        "input_string = documents[0].page_content\n",
        "metadata = documents[0].metadata\n",
        "documents = []\n",
        "\n",
        "for i in range(0, len(input_string), chunk_size - overlap):\n",
        "    chunk = input_string[i:i + chunk_size]\n",
        "    document = Document(page_content=chunk,metadata =metadata)\n",
        "    documents.append(document)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Fkx3LJOir9"
      },
      "source": [
        "##Method 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrVPtipXObhl"
      },
      "outputs": [],
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "HUAa_iQLUQGl"
      },
      "outputs": [],
      "source": [
        "api_key = \"API key\"\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "vectorstore = Chroma.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "Bjfmk-lyVLFw"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "p6RAf78hUGxI"
      },
      "outputs": [],
      "source": [
        "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
        "At the beginning of standalone question add this 'You're a chatbot designed to answer questions about Devfest hackathon.'.\n",
        "At the end of standalone question add this 'Answer the question with short, energetic, and happy-sounding responses and add emojis.\n",
        "If the question is unrelated to the context reply with 'I am sorry, I am not CHAT GPT !',\n",
        "and if you can't find the information, reply with 'I'm sorry, there is no information about it right now'.'\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"\n",
        "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "XBs7YErGVOKK"
      },
      "outputs": [],
      "source": [
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(openai_api_key=api_key,temperature=0), vectorstore.as_retriever(), memory=memory, condense_question_prompt=CONDENSE_QUESTION_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvYTbyJBVjJq"
      },
      "outputs": [],
      "source": [
        "query = \"When will DevFest be held?\"\n",
        "result = qa({\"question\": query})\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMfRAO4FdAk4"
      },
      "outputs": [],
      "source": [
        "query = \"who was the winner of the last edition ?\"\n",
        "result = qa({\"question\": query})\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaPePBlteCoE"
      },
      "outputs": [],
      "source": [
        "query = \"What is your favorite book and why?\"\n",
        "result = qa({\"question\": query})\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXSQSffqPqa6"
      },
      "source": [
        "##Test script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1JZ6PWyPxUQ"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  query = input(\"Question: \")\n",
        "  result = qa({\"question\": query})\n",
        "  print(\"Response: \"+result[\"answer\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
